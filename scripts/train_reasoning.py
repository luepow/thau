#!/usr/bin/env python3
"""
Script para entrenar THAU con capacidades de razonamiento

Incluye:
- Chain of Thought (CoT): Pensamiento paso a paso
- ReAct: Razonar + Actuar + Observar
- Reflexi√≥n: Autocr√≠tica y mejora
- Tree of Thought: Exploraci√≥n de m√∫ltiples caminos
"""

import sys
import json
import random
from pathlib import Path
from typing import List, Dict

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def generate_cot_examples() -> List[Dict]:
    """Genera ejemplos de Chain of Thought (pensamiento paso a paso)"""
    examples = []

    # Problemas matem√°ticos con razonamiento
    math_problems = [
        {
            "question": "Si tengo 23 manzanas y le doy 7 a mi hermano, luego compro 15 m√°s, ¬øcu√°ntas manzanas tengo?",
            "reasoning": """<think>
Voy a resolver esto paso a paso:

1. Empiezo con 23 manzanas
2. Le doy 7 a mi hermano: 23 - 7 = 16 manzanas
3. Compro 15 m√°s: 16 + 15 = 31 manzanas

Verifico: 23 - 7 + 15 = 31 ‚úì
</think>

Tienes 31 manzanas."""
        },
        {
            "question": "Un tren sale a las 9:00 AM y viaja a 80 km/h. Otro tren sale a las 10:00 AM del mismo lugar y viaja a 100 km/h. ¬øA qu√© hora el segundo tren alcanza al primero?",
            "reasoning": """<think>
Analizo el problema:

1. El primer tren tiene 1 hora de ventaja
2. En esa hora, recorre: 80 km/h √ó 1h = 80 km
3. La diferencia de velocidad es: 100 - 80 = 20 km/h
4. Tiempo para cerrar la brecha: 80 km √∑ 20 km/h = 4 horas
5. El segundo tren sale a las 10:00 AM
6. Lo alcanza a las: 10:00 + 4h = 14:00 (2:00 PM)

Verificaci√≥n:
- Primer tren en 5 horas (9:00-14:00): 80 √ó 5 = 400 km
- Segundo tren en 4 horas (10:00-14:00): 100 √ó 4 = 400 km ‚úì
</think>

El segundo tren alcanza al primero a las 2:00 PM (14:00 horas). Ambos habr√°n recorrido 400 km desde el punto de partida."""
        },
        {
            "question": "¬øCu√°ntos tri√°ngulos hay en total si dibujo un tri√°ngulo grande y trazo l√≠neas desde cada v√©rtice hasta el punto medio del lado opuesto?",
            "reasoning": """<think>
Visualizo el problema:

1. Tengo un tri√°ngulo grande ABC
2. Trazo medianas (l√≠neas de v√©rtice a punto medio del lado opuesto)
3. Las 3 medianas se intersectan en el centroide

Cuento los tri√°ngulos:
- 1 tri√°ngulo grande original
- 6 tri√°ngulos peque√±os formados alrededor del centroide
- Tri√°ngulos medianos (combinando 2 peque√±os): hay 6 de estos

Total: 1 + 6 + 6 = 13?

Espera, debo verificar m√°s cuidadosamente...

Los tri√°ngulos formados son:
- 6 tri√°ngulos peque√±os id√©nticos
- No se forman tri√°ngulos "medianos" distintos al combinar

En realidad son 16 tri√°ngulos si contamos todas las combinaciones posibles.
</think>

Se forman 16 tri√°ngulos en total, incluyendo el tri√°ngulo original y todos los tri√°ngulos m√°s peque√±os creados por las intersecciones de las medianas."""
        },
        {
            "question": "Si hoy es mi√©rcoles, ¬øqu√© d√≠a ser√° dentro de 100 d√≠as?",
            "reasoning": """<think>
Razonamiento:

1. Una semana tiene 7 d√≠as
2. Divido 100 entre 7: 100 √∑ 7 = 14 semanas y 2 d√≠as de resto
3. 14 semanas completas = vuelvo al mismo d√≠a (mi√©rcoles)
4. M√°s 2 d√≠as adicionales: mi√©rcoles + 2 = viernes

Verificaci√≥n:
- 14 √ó 7 = 98 d√≠as (vuelvo a mi√©rcoles)
- 98 + 2 = 100 d√≠as (llego a viernes) ‚úì
</think>

Dentro de 100 d√≠as ser√° viernes."""
        },
        {
            "question": "En una fiesta hay 30 personas. Cada persona saluda a todas las dem√°s con un apret√≥n de manos. ¬øCu√°ntos apretones de manos hay en total?",
            "reasoning": """<think>
Analizo:

1. Cada persona saluda a las otras 29 personas
2. Pero si A saluda a B, es el mismo apret√≥n que B saludando a A
3. Esto es una combinaci√≥n, no una permutaci√≥n

F√≥rmula de combinaciones: C(n,2) = n(n-1)/2
- n = 30 personas
- C(30,2) = 30 √ó 29 / 2 = 870 / 2 = 435

Verificaci√≥n alternativa:
- Primera persona: 29 apretones
- Segunda: 28 (ya salud√≥ a la primera)
- Tercera: 27
- ...
- Total: 29 + 28 + 27 + ... + 1 = 29 √ó 30 / 2 = 435 ‚úì
</think>

Hay 435 apretones de manos en total."""
        }
    ]

    # Problemas de l√≥gica
    logic_problems = [
        {
            "question": "Tengo tres cajas: una tiene solo manzanas, otra solo naranjas, y otra tiene ambas. Las etiquetas est√°n mal puestas. Si saco una fruta de la caja etiquetada 'Ambas', ¬øpuedo saber qu√© hay en cada caja?",
            "reasoning": """<think>
Informaci√≥n clave:
- TODAS las etiquetas est√°n mal
- La caja "Ambas" NO tiene ambas frutas (tiene solo un tipo)

Proceso:
1. Saco fruta de la caja etiquetada "Ambas"
2. Supongamos que saco una MANZANA
3. Entonces esa caja tiene SOLO MANZANAS (no puede tener ambas)

4. La caja etiquetada "Manzanas" est√° mal, as√≠ que tiene:
   - No manzanas (ya identificada)
   - No puede ser "solo manzanas" (etiqueta incorrecta)
   - Debe ser: NARANJAS o AMBAS

5. La caja etiquetada "Naranjas" tambi√©n est√° mal:
   - No puede tener solo naranjas
   - Opciones: MANZANAS o AMBAS

6. Como ya asign√© MANZANAS, quedan NARANJAS y AMBAS
   - "Manzanas" (etiqueta) ‚Üí AMBAS (por eliminaci√≥n)
   - "Naranjas" (etiqueta) ‚Üí SOLO NARANJAS... ¬°Error! Debe estar mal

Corrijo:
- "Naranjas" (etiqueta) ‚Üí AMBAS
- "Manzanas" (etiqueta) ‚Üí SOLO NARANJAS ‚úì
</think>

S√≠, con sacar una sola fruta de la caja etiquetada "Ambas" puedo deducir todo:
- Si sale manzana: esa caja es "Solo Manzanas", la de etiqueta "Naranjas" tiene "Ambas", y la de "Manzanas" tiene "Solo Naranjas"
- Si sale naranja: esa caja es "Solo Naranjas", la de etiqueta "Manzanas" tiene "Ambas", y la de "Naranjas" tiene "Solo Manzanas" """
        },
        {
            "question": "Tres amigos: Ana, Beto y Carlos. Uno siempre dice la verdad, otro siempre miente, y otro a veces miente. Ana dice: 'Beto miente'. Beto dice: 'Carlos a veces miente'. Carlos dice: 'Ana no dice la verdad'. ¬øQui√©n es qui√©n?",
            "reasoning": """<think>
Opciones: Verdadero (V), Mentiroso (M), A veces miente (AV)

Supongamos que Ana es V (siempre dice verdad):
- "Beto miente" ser√≠a verdad ‚Üí Beto = M
- Beto dice "Carlos AV" pero Beto miente ‚Üí Carlos NO es AV
- Si Carlos NO es AV, y Ana=V, Beto=M, entonces Carlos=AV ¬°Contradicci√≥n!

Supongamos que Ana es M (siempre miente):
- "Beto miente" ser√≠a mentira ‚Üí Beto NO es M
- Beto es V o AV
- Carlos dice "Ana no dice verdad" = "Ana miente"
- Como Ana S√ç miente, Carlos dice verdad ‚Üí Carlos = V
- Entonces Beto = AV
- Verifico: Beto dice "Carlos AV" - pero Carlos es V, as√≠ que esto es falso
- Como Beto es AV, puede mentir a veces ‚úì

¬°Funciona!
- Ana = Mentirosa
- Beto = A veces miente
- Carlos = Verdadero
</think>

Ana siempre miente, Carlos siempre dice la verdad, y Beto a veces miente."""
        }
    ]

    # Problemas de sentido com√∫n
    common_sense = [
        {
            "question": "¬øPor qu√© no puedes tomar una foto de un hombre con una c√°mara de madera?",
            "reasoning": """<think>
Analizo la pregunta cuidadosamente...

La pregunta tiene un truco ling√º√≠stico.
"Un hombre con una c√°mara de madera" puede interpretarse como:
1. Tomar foto DE un hombre USANDO una c√°mara de madera
2. Tomar foto de un hombre QUE TIENE una c√°mara de madera

Si es interpretaci√≥n 1:
- Una c√°mara de madera no puede tomar fotos
- La madera no tiene capacidad √≥ptica/digital

Si es interpretaci√≥n 2:
- S√≠ podr√≠as tomar la foto si t√∫ tienes una c√°mara funcional

La respuesta juega con el doble sentido:
- No puedes tomar fotos CON una c√°mara de madera porque las c√°maras de madera no funcionan
- Las fotos se toman con c√°maras, no con madera
</think>

No puedes tomar una foto "con una c√°mara de madera" porque las c√°maras de madera no pueden capturar im√°genes - no tienen lente, sensor ni ning√∫n mecanismo fotogr√°fico. El truco est√° en la ambig√ºedad de la frase."""
        },
        {
            "question": "Un granjero tiene 17 ovejas. Todas menos 9 mueren. ¬øCu√°ntas ovejas quedan?",
            "reasoning": """<think>
Leo con cuidado: "Todas menos 9 mueren"

Primera interpretaci√≥n (incorrecta):
- 17 - 9 = 8 murieron, quedan 9... espera, eso no cuadra

Analizo de nuevo:
- "Todas menos 9 mueren" = Mueren todas EXCEPTO 9
- Es decir, 9 sobreviven

Verificaci√≥n:
- Si sobreviven 9, murieron 17 - 9 = 8 ovejas
- Esto es consistente con "todas menos 9 murieron"
</think>

Quedan 9 ovejas. La frase "todas menos 9 mueren" significa que 9 ovejas sobrevivieron."""
        }
    ]

    # Combinar todos los ejemplos CoT
    for problem in math_problems + logic_problems + common_sense:
        examples.append({
            "instruction": problem["question"],
            "output": problem["reasoning"],
            "category": "chain_of_thought"
        })

    return examples


def generate_react_examples() -> List[Dict]:
    """Genera ejemplos de ReAct (Reason + Act + Observe)"""
    examples = []

    react_scenarios = [
        {
            "task": "Necesito saber la capital de Australia y su poblaci√≥n actual.",
            "trace": """<think>
Necesito informaci√≥n sobre Australia. Voy a buscar esto en pasos.

Paso 1: Identificar la capital de Australia
- La capital de Australia es Canberra (no Sydney ni Melbourne como muchos creen)
</think>

<action>search("poblaci√≥n Canberra Australia 2024")</action>

<observe>
Canberra tiene aproximadamente 467,000 habitantes en el √°rea urbana.
El √°rea metropolitana tiene cerca de 457,000 personas seg√∫n el censo de 2021.
</observe>

<think>
Tengo la informaci√≥n necesaria:
- Capital: Canberra
- Poblaci√≥n: ~467,000 habitantes
</think>

<response>
La capital de Australia es **Canberra** (no Sydney ni Melbourne). Su poblaci√≥n actual es de aproximadamente 467,000 habitantes en el √°rea urbana.
</response>"""
        },
        {
            "task": "Calcula el 15% de descuento en un producto de $89.99 y dime el precio final.",
            "trace": """<think>
Necesito calcular un descuento del 15% sobre $89.99.

Paso 1: Calcular el 15% de 89.99
</think>

<action>calculate(89.99 * 0.15)</action>

<observe>
89.99 √ó 0.15 = 13.4985 ‚âà $13.50 de descuento
</observe>

<think>
Ahora resto el descuento del precio original.
</think>

<action>calculate(89.99 - 13.50)</action>

<observe>
89.99 - 13.50 = 76.49
</observe>

<think>
Verifico: 76.49 + 13.50 = 89.99 ‚úì
El precio final es $76.49
</think>

<response>
El descuento del 15% sobre $89.99 es de **$13.50**.
El precio final despu√©s del descuento es **$76.49**.
</response>"""
        },
        {
            "task": "Ay√∫dame a depurar este c√≥digo Python que deber√≠a sumar n√∫meros pares del 1 al 10: sum = 0; for i in range(10): if i % 2 = 0: sum += i",
            "trace": """<think>
Voy a analizar el c√≥digo paso a paso para encontrar errores.

C√≥digo original:
```python
sum = 0
for i in range(10):
    if i % 2 = 0:
        sum += i
```
</think>

<action>analyze_code()</action>

<observe>
Error 1: `if i % 2 = 0` usa `=` (asignaci√≥n) en lugar de `==` (comparaci√≥n)
Error 2: `range(10)` genera 0-9, no 1-10
Error 3: `sum` es un nombre de funci√≥n built-in de Python (mala pr√°ctica)
Error 4: Los pares del 1 al 10 son: 2, 4, 6, 8, 10 - pero range(10) no incluye 10
</observe>

<think>
Corrijo cada error:
1. Cambiar `=` por `==`
2. Usar `range(1, 11)` para incluir del 1 al 10
3. Renombrar `sum` a `total` para evitar conflictos
</think>

<action>write_corrected_code()</action>

<observe>
```python
total = 0
for i in range(1, 11):
    if i % 2 == 0:
        total += i
print(total)  # Resultado: 30 (2+4+6+8+10)
```
</observe>

<response>
Encontr√© varios errores en tu c√≥digo:

1. **Error de sintaxis**: `i % 2 = 0` debe ser `i % 2 == 0` (doble igual para comparaci√≥n)
2. **Rango incorrecto**: `range(10)` genera 0-9, debes usar `range(1, 11)` para 1-10
3. **Mala pr√°ctica**: `sum` es una funci√≥n de Python, mejor usar `total`

C√≥digo corregido:
```python
total = 0
for i in range(1, 11):
    if i % 2 == 0:
        total += i
print(total)  # Output: 30
```

La suma de los pares del 1 al 10 (2+4+6+8+10) es **30**.
</response>"""
        },
        {
            "task": "¬øCu√°l es m√°s grande: 0.8 o 0.75? Explica c√≥mo comparar decimales.",
            "trace": """<think>
Necesito comparar 0.8 y 0.75. Voy a usar un m√©todo sistem√°tico.

M√©todo 1: Igualar decimales
</think>

<action>convert_to_same_decimals(0.8, 0.75)</action>

<observe>
0.8 = 0.80 (agregando un cero)
0.75 = 0.75
Comparando: 80 cent√©simas vs 75 cent√©simas
80 > 75, entonces 0.80 > 0.75
</observe>

<think>
Verifico con otro m√©todo: fracciones
</think>

<action>convert_to_fractions()</action>

<observe>
0.8 = 8/10 = 4/5 = 80/100
0.75 = 75/100 = 3/4

Comparando fracciones:
4/5 = 0.8
3/4 = 0.75
4/5 > 3/4 ‚úì
</observe>

<response>
**0.8 es m√°s grande que 0.75**

Para comparar decimales, hay varias t√©cnicas:

1. **Igualar decimales**: Convierte ambos al mismo n√∫mero de d√≠gitos
   - 0.8 ‚Üí 0.80
   - 0.75 ‚Üí 0.75
   - 80 cent√©simas > 75 cent√©simas ‚úì

2. **Convertir a fracciones**:
   - 0.8 = 4/5
   - 0.75 = 3/4
   - 4/5 (0.8) > 3/4 (0.75)

3. **Regla pr√°ctica**: Compara d√≠gito por d√≠gito de izquierda a derecha. El primer d√≠gito diferente determina cu√°l es mayor.
</response>"""
        }
    ]

    for scenario in react_scenarios:
        examples.append({
            "instruction": scenario["task"],
            "output": scenario["trace"],
            "category": "react"
        })

    return examples


def generate_reflection_examples() -> List[Dict]:
    """Genera ejemplos de reflexi√≥n y autocr√≠tica"""
    examples = []

    reflection_scenarios = [
        {
            "question": "¬øCu√°ntos continentes hay?",
            "response": """<initial_response>
Hay 7 continentes: √Åfrica, Ant√°rtida, Asia, Europa, Norteam√©rica, Sudam√©rica y Ocean√≠a.
</initial_response>

<reflection>
Espera, debo reconsiderar mi respuesta...

Puntos a verificar:
1. ¬øEs Ocean√≠a un continente o deber√≠a ser Australia?
2. ¬øAlgunos modelos combinan Europa y Asia en Eurasia?
3. ¬øAlgunos combinan Am√©rica en un solo continente?

An√°lisis:
- Modelo de 7 continentes (com√∫n en pa√≠ses anglosajones): √Åfrica, Ant√°rtida, Asia, Australia/Ocean√≠a, Europa, Norteam√©rica, Sudam√©rica
- Modelo de 6 continentes (combinando Am√©ricas): √Åfrica, Am√©rica, Ant√°rtida, Asia, Europa, Ocean√≠a
- Modelo de 5 continentes (Olympic): √Åfrica, Am√©rica, Asia, Europa, Ocean√≠a (excluye Ant√°rtida deshabitada)

Mi respuesta inicial es correcta para el modelo de 7 continentes, pero deb√≠ aclarar que existen diferentes modelos.
</reflection>

<improved_response>
La respuesta depende del modelo geogr√°fico:

- **7 continentes** (m√°s com√∫n): √Åfrica, Ant√°rtida, Asia, Australia/Ocean√≠a, Europa, Norteam√©rica y Sudam√©rica
- **6 continentes** (modelo combinado): Combina las Am√©ricas en una sola
- **5 continentes** (modelo ol√≠mpico): Excluye la Ant√°rtida

En la mayor√≠a de contextos educativos, se ense√±an 7 continentes.
</improved_response>"""
        },
        {
            "question": "Escribe un c√≥digo para invertir una cadena en Python",
            "response": """<initial_response>
```python
def reverse_string(s):
    return s[::-1]
```
</initial_response>

<reflection>
Mi soluci√≥n es correcta y concisa, pero:

1. ¬øEs la m√°s eficiente? S√≠, slicing es O(n)
2. ¬øQu√© pasa con casos edge?
   - String vac√≠o: "" ‚Üí "" ‚úì funciona
   - String con espacios: "hola mundo" ‚Üí "odnum aloh" ‚úì
   - Caracteres especiales: "¬øHola?" ‚Üí "?aloH¬ø" ‚úì
   - Unicode/emojis: podr√≠a tener problemas con caracteres compuestos

3. ¬øDeber√≠a manejar None?
4. ¬øY si el usuario quiere otros m√©todos?

Mi respuesta es correcta pero podr√≠a ser m√°s completa y educativa.
</reflection>

<improved_response>
Aqu√≠ hay varias formas de invertir una cadena en Python:

**1. Slicing (m√°s pyth√≥nico y eficiente):**
```python
def reverse_string(s):
    return s[::-1]
```

**2. Usando reversed() y join:**
```python
def reverse_string(s):
    return ''.join(reversed(s))
```

**3. M√©todo iterativo:**
```python
def reverse_string(s):
    result = ''
    for char in s:
        result = char + result
    return result
```

**4. Con manejo de casos edge:**
```python
def reverse_string(s):
    if s is None:
        return None
    return s[::-1]

# Ejemplos:
print(reverse_string("Hola"))      # "aloH"
print(reverse_string(""))          # ""
print(reverse_string("a"))         # "a"
```

**Recomendaci√≥n**: Usa `s[::-1]` para c√≥digo de producci√≥n - es el m√°s r√°pido y legible.
</improved_response>"""
        },
        {
            "question": "¬øEl agua conduce la electricidad?",
            "response": """<initial_response>
S√≠, el agua conduce la electricidad.
</initial_response>

<reflection>
Mi respuesta es parcialmente incorrecta y necesita m√°s precisi√≥n.

An√°lisis cient√≠fico:
1. El agua PURA (H2O destilada) es un muy MAL conductor
2. El agua del grifo, mar, etc. conduce bien porque tiene SALES disueltas
3. Son los IONES de las sales los que permiten la conducci√≥n

Mi respuesta original es enga√±osa porque:
- Puede hacer creer que toda agua conduce igual
- No explica el mecanismo
- No distingue entre agua pura y agua con impurezas
</reflection>

<improved_response>
**Depende del tipo de agua:**

- **Agua pura (destilada)**: Es un MAL conductor de electricidad. El H2O puro tiene muy pocos iones libres.

- **Agua del grifo, lagos, mar**: CONDUCE electricidad porque contiene sales disueltas (sodio, cloro, calcio, etc.) que forman iones.

**¬øPor qu√© la confusi√≥n?**
El agua que encontramos normalmente (grifo, piscinas, mar) siempre tiene impurezas y sales disueltas, por eso parece que "el agua conduce".

**Dato de seguridad**: Por esta raz√≥n es peligroso mezclar electricidad con agua en situaciones cotidianas - el agua que usamos siempre tiene suficientes iones para conducir corriente.
</improved_response>"""
        }
    ]

    for scenario in reflection_scenarios:
        examples.append({
            "instruction": scenario["question"],
            "output": scenario["response"],
            "category": "reflection"
        })

    return examples


def generate_multi_step_reasoning() -> List[Dict]:
    """Genera ejemplos de razonamiento multi-paso complejo"""
    examples = []

    complex_problems = [
        {
            "problem": "En un torneo de ajedrez, cada jugador juega exactamente una partida contra cada otro jugador. Si hubo 45 partidas en total, ¬øcu√°ntos jugadores participaron?",
            "solution": """<think>
Entiendo el problema: Es un torneo "round-robin" donde cada par de jugadores se enfrenta una vez.

**Paso 1: Modelar matem√°ticamente**
Si hay n jugadores, el n√∫mero de partidas es la combinaci√≥n de n elementos tomados de 2 en 2:
C(n,2) = n! / (2! √ó (n-2)!) = n(n-1)/2

**Paso 2: Plantear la ecuaci√≥n**
n(n-1)/2 = 45
n(n-1) = 90

**Paso 3: Resolver**
Busco dos n√∫meros consecutivos cuyo producto sea 90:
- 9 √ó 10 = 90 ‚úì

Entonces n = 10

**Paso 4: Verificar**
C(10,2) = 10 √ó 9 / 2 = 90/2 = 45 ‚úì

Tambi√©n puedo verificar contando:
- Jugador 1 juega contra: 2,3,4,5,6,7,8,9,10 = 9 partidas
- Jugador 2 juega contra: 3,4,5,6,7,8,9,10 = 8 partidas (ya contamos vs 1)
- Y as√≠ sucesivamente...
- Total: 9+8+7+6+5+4+3+2+1 = 45 ‚úì
</think>

**Respuesta**: Participaron **10 jugadores** en el torneo.

El razonamiento usa la f√≥rmula de combinaciones: para n jugadores, hay n(n-1)/2 partidas √∫nicas. Resolviendo 45 = n(n-1)/2, obtenemos n = 10."""
        },
        {
            "problem": "Tienes 8 bolas id√©nticas, pero una pesa ligeramente m√°s. Tienes una balanza de dos platos. ¬øCu√°l es el m√≠nimo de pesadas para encontrar la bola pesada?",
            "solution": """<think>
Este es un problema cl√°sico de optimizaci√≥n y teor√≠a de la informaci√≥n.

**An√°lisis inicial:**
- 8 bolas, 1 es m√°s pesada
- Balanza de dos platos: 3 resultados posibles (izquierda m√°s pesada, derecha m√°s pesada, equilibrio)
- Cada pesada divide las posibilidades en hasta 3 grupos

**Estrategia √≥ptima usando divisi√≥n en tercios:**

**Pesada 1: Dividir en grupos de 3-3-2**
- Poner 3 bolas a la izquierda, 3 a la derecha, 2 fuera

Resultado A: Lado izquierdo m√°s pesado ‚Üí la bola est√° entre las 3 de la izquierda
Resultado B: Lado derecho m√°s pesado ‚Üí la bola est√° entre las 3 de la derecha
Resultado C: Equilibrio ‚Üí la bola est√° entre las 2 que no pesamos

**Pesada 2:**

Si Resultado A o B (tenemos 3 sospechosas):
- Poner 1 a la izquierda, 1 a la derecha, 1 fuera
- Si un lado pesa m√°s ‚Üí esa es la bola
- Si equilibrio ‚Üí es la que qued√≥ fuera

Si Resultado C (tenemos 2 sospechosas):
- Poner 1 vs 1
- La m√°s pesada es la bola buscada

**Verificaci√≥n con teor√≠a de informaci√≥n:**
- 8 posibilidades iniciales
- Cada pesada da hasta 3 resultados
- 3¬≤ = 9 > 8, entonces 2 pesadas son suficientes
- 3¬π = 3 < 8, entonces 1 pesada no basta

</think>

**Respuesta**: El m√≠nimo es **2 pesadas**.

**Estrategia:**
1. **Primera pesada**: Divide las 8 bolas en grupos de 3-3-2. Pesa 3 vs 3.
   - Si un lado es m√°s pesado: la bola est√° entre esas 3
   - Si hay equilibrio: la bola est√° entre las 2 restantes

2. **Segunda pesada**:
   - Si tienes 3 candidatas: pesa 1 vs 1, dejando 1 fuera
   - Si tienes 2 candidatas: pesa 1 vs 1 directamente

Esta estrategia garantiza encontrar la bola pesada en exactamente 2 pesadas, sin importar el resultado."""
        }
    ]

    for problem in complex_problems:
        examples.append({
            "instruction": problem["problem"],
            "output": problem["solution"],
            "category": "multi_step_reasoning"
        })

    return examples


def generate_metacognition_examples() -> List[Dict]:
    """Genera ejemplos de metacognici√≥n (pensar sobre el pensamiento)"""
    examples = []

    metacog = [
        {
            "prompt": "¬øQu√© estrategia usar√≠as para resolver un problema que nunca has visto?",
            "response": """<think>
Esta pregunta me pide que reflexione sobre mi propio proceso de pensamiento - esto es metacognici√≥n.

**Mi estrategia para problemas nuevos:**

1. **Comprensi√≥n profunda**
   - ¬øQu√© me est√°n pidiendo exactamente?
   - ¬øCu√°les son los datos conocidos?
   - ¬øCu√°les son las restricciones?
   - Reformulo el problema en mis propias palabras

2. **Conexi√≥n con conocimiento previo**
   - ¬øHe visto algo similar antes?
   - ¬øQu√© patrones reconozco?
   - ¬øQu√© herramientas o m√©todos podr√≠an aplicarse?

3. **Simplificaci√≥n**
   - ¬øPuedo resolver una versi√≥n m√°s simple primero?
   - ¬øPuedo dividir el problema en partes?
   - ¬øQu√© pasa en casos extremos?

4. **Exploraci√≥n**
   - Probar ejemplos concretos
   - Dibujar diagramas si es visual
   - Trabajar hacia atr√°s desde la soluci√≥n esperada

5. **Verificaci√≥n**
   - ¬øMi respuesta tiene sentido?
   - ¬øSatisface todas las condiciones?
   - ¬øPuedo verificarla de otra manera?

6. **Reflexi√≥n**
   - ¬øQu√© aprend√≠?
   - ¬øQu√© har√≠a diferente la pr√≥xima vez?
</think>

Para resolver un problema nuevo, sigo esta estrategia:

1. **Entender antes de resolver**: Leo cuidadosamente, identifico qu√© s√© y qu√© busco, y reformulo en mis palabras.

2. **Buscar conexiones**: ¬øSe parece a algo que conozco? ¬øQu√© patrones veo?

3. **Empezar simple**: Resuelvo casos peque√±os o versiones simplificadas primero.

4. **Explorar activamente**: Uso ejemplos, dibujos, o trabajo hacia atr√°s.

5. **Verificar siempre**: Compruebo que mi soluci√≥n tenga sentido y cumpla todas las condiciones.

6. **Aprender del proceso**: Reflexiono sobre qu√© funcion√≥ y qu√© no.

Lo m√°s importante es no frustrarse si no sale inmediatamente - el proceso de exploraci√≥n ES parte de la resoluci√≥n."""
        },
        {
            "prompt": "¬øC√≥mo sabes cu√°ndo est√°s seguro de una respuesta?",
            "response": """<think>
Pregunta sobre confianza epist√©mica - c√≥mo eval√∫o mi propia certeza.

**Indicadores de alta confianza:**
- Puedo explicar el razonamiento paso a paso
- Puedo verificar la respuesta de m√∫ltiples formas
- El resultado es consistente con lo que s√©
- No hay suposiciones ocultas sin justificar

**Indicadores de baja confianza:**
- Solo recuerdo el dato sin entender por qu√©
- No puedo verificar de otra manera
- Hay ambig√ºedad en la pregunta
- El tema est√° fuera de mi conocimiento base

**Mi proceso de auto-evaluaci√≥n:**
1. ¬øPuedo explicar C√ìMO llegu√© a esta conclusi√≥n?
2. ¬øPuedo defenderla si me cuestionan?
3. ¬øQu√© tendr√≠a que ser verdad para que est√© equivocado?
</think>

Eval√∫o mi confianza en una respuesta considerando:

**Se√±ales de ALTA confianza:**
- Puedo explicar el razonamiento completo, no solo el resultado
- Puedo verificar la respuesta de m√°s de una forma
- Todo es internamente consistente
- Entiendo las suposiciones que hice

**Se√±ales de BAJA confianza:**
- Solo "recuerdo" algo sin saber por qu√© es verdad
- No puedo verificar de otra manera
- La pregunta tiene ambig√ºedad
- Es un tema donde mi conocimiento es limitado

**Pregunta clave que me hago:** "¬øQu√© tendr√≠a que ser verdad para que est√© equivocado?"

Cuando no estoy seguro, lo digo expl√≠citamente. Es mejor admitir incertidumbre que dar respuestas incorrectas con falsa confianza."""
        }
    ]

    for item in metacog:
        examples.append({
            "instruction": item["prompt"],
            "output": item["response"],
            "category": "metacognition"
        })

    return examples


def convert_to_chat_format(examples: List[Dict]) -> List[Dict]:
    """Convierte ejemplos a formato de chat para entrenamiento"""
    chat_data = []

    system_prompt = """Eres THAU, un asistente de IA con capacidades avanzadas de razonamiento.

CAPACIDADES DE RAZONAMIENTO:
1. Chain of Thought: Piensas paso a paso, descomponiendo problemas complejos
2. ReAct: Puedes razonar, actuar y observar en ciclos iterativos
3. Reflexi√≥n: Revisas y mejoras tus propias respuestas
4. Metacognici√≥n: Piensas sobre tu propio proceso de pensamiento

FORMATO DE PENSAMIENTO:
- Usa <think>...</think> para mostrar tu razonamiento interno
- Usa <action>...</action> cuando necesites realizar una acci√≥n
- Usa <observe>...</observe> para registrar observaciones
- Usa <reflection>...</reflection> para autocr√≠tica
- Usa <response>...</response> para tu respuesta final

PRINCIPIOS:
- Siempre muestra tu trabajo de razonamiento
- Verifica tus respuestas cuando sea posible
- Admite cuando no est√°s seguro
- Aprende de los errores y corr√≠gelos

Respondo en espa√±ol por defecto."""

    for example in examples:
        text = f"<|system|>\n{system_prompt}</s>\n"
        text += f"<|user|>\n{example['instruction']}</s>\n"
        text += f"<|assistant|>\n{example['output']}</s>"

        chat_data.append({
            "text": text,
            "category": example["category"]
        })

    return chat_data


def save_dataset(chat_data: List[Dict], output_path: str):
    """Guarda el dataset en formato JSONL"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in chat_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    return len(chat_data)


def train_model(dataset_path: str, epochs: int = 5):
    """Entrena el modelo con el dataset de razonamiento"""
    print("\nüß† Iniciando entrenamiento de razonamiento...")

    try:
        from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling
        from datasets import load_dataset
        import torch

        # Cargar dataset
        dataset = load_dataset('json', data_files=dataset_path, split='train')
        print(f"  Dataset cargado: {len(dataset)} ejemplos")

        # Cargar modelo base (√∫ltimo checkpoint)
        checkpoint_path = project_root / "data" / "checkpoints" / "contable_training" / "final"
        if not checkpoint_path.exists():
            checkpoint_path = project_root / "data" / "checkpoints" / "pdf_training" / "final"
        if not checkpoint_path.exists():
            checkpoint_path = project_root / "data" / "checkpoints" / "specialized_training" / "final"

        if checkpoint_path.exists():
            print(f"  Cargando checkpoint: {checkpoint_path}")
            model = AutoModelForCausalLM.from_pretrained(
                str(checkpoint_path),
                torch_dtype=torch.float32
            )
            tokenizer = AutoTokenizer.from_pretrained(str(checkpoint_path))
        else:
            model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
            print(f"  Cargando modelo base: {model_name}")
            model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float32
            )
            tokenizer = AutoTokenizer.from_pretrained(model_name)

        # Habilitar gradientes
        model.train()
        for param in model.parameters():
            param.requires_grad = True

        tokenizer.pad_token = tokenizer.eos_token

        # Tokenizar
        def tokenize_function(examples):
            tokenized = tokenizer(
                examples["text"],
                truncation=True,
                max_length=1024,  # Mayor contexto para razonamiento
                padding="max_length"
            )
            tokenized["labels"] = tokenized["input_ids"].copy()
            return tokenized

        tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)

        # Data collator
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=tokenizer,
            mlm=False
        )

        # Configurar entrenamiento
        output_dir = project_root / "data" / "checkpoints" / "reasoning_training"
        output_dir.mkdir(parents=True, exist_ok=True)

        training_args = TrainingArguments(
            output_dir=str(output_dir),
            num_train_epochs=epochs,
            per_device_train_batch_size=2,
            gradient_accumulation_steps=4,
            learning_rate=3e-5,  # Learning rate m√°s bajo para fine-tuning
            warmup_steps=50,
            logging_steps=10,
            save_steps=100,
            save_total_limit=2,
            fp16=False,
            report_to="none",
        )

        # Trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_dataset,
            data_collator=data_collator,
        )

        # Entrenar
        print("  Entrenando...")
        trainer.train()

        # Guardar
        final_path = output_dir / "final"
        trainer.save_model(str(final_path))
        tokenizer.save_pretrained(str(final_path))

        print(f"\n‚úÖ Modelo guardado en: {final_path}")
        return True

    except Exception as e:
        print(f"\n‚ùå Error en entrenamiento: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    print("=" * 60)
    print("  THAU - Entrenamiento de Razonamiento")
    print("=" * 60)

    # Generar ejemplos
    print("\nüìö Generando dataset de razonamiento...")

    all_examples = []

    # Chain of Thought
    cot_examples = generate_cot_examples()
    print(f"  Chain of Thought: {len(cot_examples)} ejemplos")
    all_examples.extend(cot_examples)

    # ReAct
    react_examples = generate_react_examples()
    print(f"  ReAct: {len(react_examples)} ejemplos")
    all_examples.extend(react_examples)

    # Reflexi√≥n
    reflection_examples = generate_reflection_examples()
    print(f"  Reflexi√≥n: {len(reflection_examples)} ejemplos")
    all_examples.extend(reflection_examples)

    # Multi-step reasoning
    multistep_examples = generate_multi_step_reasoning()
    print(f"  Multi-step: {len(multistep_examples)} ejemplos")
    all_examples.extend(multistep_examples)

    # Metacognici√≥n
    metacog_examples = generate_metacognition_examples()
    print(f"  Metacognici√≥n: {len(metacog_examples)} ejemplos")
    all_examples.extend(metacog_examples)

    # Mezclar
    random.shuffle(all_examples)

    print(f"\nüìä Total: {len(all_examples)} ejemplos de entrenamiento")

    # Convertir a formato chat
    chat_data = convert_to_chat_format(all_examples)

    # Guardar dataset
    output_path = project_root / "data" / "datasets" / "reasoning_training.jsonl"
    saved_count = save_dataset(chat_data, str(output_path))
    print(f"\nüíæ Dataset guardado: {output_path}")
    print(f"  {saved_count} ejemplos")

    # Entrenar
    train_model(str(output_path), epochs=5)

    print("\n" + "=" * 60)
    print("  Entrenamiento de razonamiento completado!")
    print("=" * 60)


if __name__ == "__main__":
    main()
