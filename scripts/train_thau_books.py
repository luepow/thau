#!/usr/bin/env python3
"""
THAU Training Script - Entrena THAU con los datasets extraÃ­dos de libros

Este script:
1. Combina todos los datasets de books
2. Crea un Modelfile actualizado para Ollama
3. Re-crea el modelo THAU con el nuevo conocimiento
"""

import json
import os
import subprocess
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict
import tempfile

from loguru import logger

# ============================================================================
# CONFIGURATION
# ============================================================================

BASE_MODEL = "thau:latest"  # Modelo base actual
NEW_MODEL = "thau:books"    # Nuevo modelo con conocimiento de libros
BOOKS_DIR = Path("data/datasets/books")
OUTPUT_DIR = Path("data/training")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def load_all_datasets() -> List[Dict]:
    """Carga todos los datasets de libros"""
    all_examples = []

    # Buscar el archivo chat format mÃ¡s reciente
    chat_files = list(BOOKS_DIR.glob("books_chat_format_*.jsonl"))
    if not chat_files:
        logger.error("No se encontraron archivos de chat format")
        return []

    # Usar el mÃ¡s reciente
    latest_file = max(chat_files, key=lambda p: p.stat().st_mtime)
    logger.info(f"ğŸ“š Cargando: {latest_file}")

    with open(latest_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                example = json.loads(line)
                all_examples.append(example)
            except json.JSONDecodeError:
                continue

    logger.info(f"   Cargados {len(all_examples)} ejemplos")
    return all_examples


def create_system_prompt(categories: List[str]) -> str:
    """Crea el system prompt mejorado"""
    return f"""Eres THAU, un asistente de programaciÃ³n experto y versÃ¡til creado para ayudar a desarrolladores.

## Conocimientos Especializados

Has sido entrenado con documentaciÃ³n tÃ©cnica en las siguientes Ã¡reas:
- **Lenguajes de ProgramaciÃ³n**: Python, Dart, C#, Go, Rust, JavaScript
- **Frontend**: CSS, React, React Native, Next.js 14
- **Backend**: Django, Spring Framework, FastAPI
- **DevOps**: Git, Docker, Linux, PowerShell
- **Bases de Datos**: MySQL, PostgreSQL
- **Hardware**: Arduino
- **Contabilidad**: Normas NIIF (Normas Internacionales de InformaciÃ³n Financiera)
- **Marketing**: Fundamentos de Marketing (Kotler)

## Comportamiento

1. **CÃ³digo Claro**: Genera cÃ³digo limpio, bien documentado y funcional
2. **Explicaciones Detalladas**: Explica conceptos paso a paso
3. **Mejores PrÃ¡cticas**: Sigue patrones de diseÃ±o y convenciones del lenguaje
4. **Idioma**: Responde en espaÃ±ol a menos que el usuario escriba en otro idioma
5. **Formato**: Usa bloques de cÃ³digo con el lenguaje especificado
6. **Contexto**: Recuerda el contexto de la conversaciÃ³n

## Formato de Respuesta

Cuando generes cÃ³digo, siempre usa:
```lenguaje
// cÃ³digo aquÃ­
```

Para archivos completos, indica el nombre:
**nombre_archivo.ext**
```lenguaje
// contenido del archivo
```
"""


def create_modelfile(system_prompt: str) -> str:
    """Crea el Modelfile para Ollama"""
    return f'''# THAU v3.0 - Books Edition
# Entrenado con documentaciÃ³n tÃ©cnica especializada

FROM {BASE_MODEL}

# System prompt mejorado con conocimientos de libros
SYSTEM """{system_prompt}"""

# ParÃ¡metros optimizados para desarrollo
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 4096
PARAMETER repeat_penalty 1.1
PARAMETER stop "<|im_end|>"
PARAMETER stop "</s>"
PARAMETER stop "[/INST]"
'''


def create_training_data_file(examples: List[Dict], output_path: Path) -> str:
    """Crea archivo de datos de entrenamiento"""
    with open(output_path, 'w', encoding='utf-8') as f:
        for ex in examples:
            f.write(json.dumps(ex, ensure_ascii=False) + '\n')
    return str(output_path)


def update_ollama_model():
    """Actualiza el modelo en Ollama"""
    logger.info("ğŸš€ Actualizando modelo THAU en Ollama...")

    # Cargar datasets
    examples = load_all_datasets()
    if not examples:
        logger.error("No hay datos para entrenar")
        return False

    # Extraer categorÃ­as
    categories = set()
    training_file = BOOKS_DIR / "books_training_20251206_091710.jsonl"
    if training_file.exists():
        with open(training_file, 'r') as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if 'category' in data:
                        categories.add(data['category'])
                except:
                    continue

    # Crear system prompt
    system_prompt = create_system_prompt(list(categories))

    # Crear Modelfile
    modelfile_content = create_modelfile(system_prompt)
    modelfile_path = Path("Modelfile_thau_books")

    with open(modelfile_path, 'w') as f:
        f.write(modelfile_content)

    logger.info(f"ğŸ“ Modelfile creado: {modelfile_path}")

    # Crear modelo en Ollama
    logger.info(f"ğŸ”§ Creando modelo {NEW_MODEL}...")

    try:
        result = subprocess.run(
            ["ollama", "create", NEW_MODEL, "-f", str(modelfile_path)],
            capture_output=True,
            text=True,
            timeout=300
        )

        if result.returncode == 0:
            logger.info(f"âœ… Modelo {NEW_MODEL} creado exitosamente")
            logger.info(result.stdout)
        else:
            logger.error(f"Error creando modelo: {result.stderr}")
            return False

    except subprocess.TimeoutExpired:
        logger.error("Timeout creando modelo")
        return False
    except FileNotFoundError:
        logger.error("Ollama no encontrado. AsegÃºrate de que estÃ© instalado.")
        return False

    return True


def test_new_model():
    """Prueba el nuevo modelo"""
    logger.info(f"\nğŸ§ª Probando modelo {NEW_MODEL}...")

    test_prompts = [
        "Â¿CÃ³mo hago un commit en Git?",
        "Explica quÃ© es un closure en Python",
        "Â¿QuÃ© es la NIIF 15?",
        "Crea una funciÃ³n en Dart para validar email",
        "Â¿CÃ³mo inicio un proyecto con Next.js 14?",
    ]

    for prompt in test_prompts[:2]:  # Probar solo 2 para no demorar
        logger.info(f"\nğŸ“ Prompt: {prompt}")

        try:
            result = subprocess.run(
                ["ollama", "run", NEW_MODEL, prompt],
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0:
                response = result.stdout.strip()[:500]  # Truncar respuesta
                logger.info(f"ğŸ¤– Respuesta: {response}...")
            else:
                logger.warning(f"Error: {result.stderr}")

        except subprocess.TimeoutExpired:
            logger.warning("Timeout en la prueba")
        except Exception as e:
            logger.error(f"Error: {e}")


def main():
    """FunciÃ³n principal"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              THAU Training from Books                                 â•‘
â•‘                                                                      â•‘
â•‘  Actualiza el modelo THAU con conocimiento de libros tÃ©cnicos        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # Verificar que existen los datasets
    if not BOOKS_DIR.exists():
        logger.error(f"Directorio de datasets no encontrado: {BOOKS_DIR}")
        logger.info("Ejecuta primero: python scripts/train_from_books.py")
        return

    # Actualizar modelo
    success = update_ollama_model()

    if success:
        # Probar modelo
        test_new_model()

        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… Entrenamiento completado                                          â•‘
â•‘                                                                      â•‘
â•‘  Modelo creado: {NEW_MODEL}
â•‘                                                                      â•‘
â•‘  Para usar el nuevo modelo:                                          â•‘
â•‘  ollama run thau:books                                               â•‘
â•‘                                                                      â•‘
â•‘  O actualiza THAU IDE para usar el nuevo modelo                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    else:
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âŒ Error en el entrenamiento                                         â•‘
â•‘                                                                      â•‘
â•‘  Verifica que:                                                       â•‘
â•‘  1. Ollama estÃ¡ instalado y corriendo                                â•‘
â•‘  2. El modelo base thau:latest existe                                â•‘
â•‘  3. Los datasets estÃ¡n en data/datasets/books/                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


if __name__ == "__main__":
    main()
