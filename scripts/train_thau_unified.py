#!/usr/bin/env python3
"""
THAU Unified Training Script
Combina TODOS los datasets en un solo modelo unificado: thau-1.1b
"""

import json
import os
import subprocess
from pathlib import Path
from datetime import datetime
from typing import List, Dict

# ConfiguraciÃ³n
DATASETS_DIR = Path(__file__).parent.parent / "data" / "datasets"
OUTPUT_DIR = Path(__file__).parent.parent / "data" / "datasets"
MODELFILE_DIR = Path(__file__).parent.parent

# Todos los datasets disponibles para combinar
DATASETS_TO_COMBINE = [
    # ProgramaciÃ³n
    "programming_chat_format.jsonl",
    "programming_combined_20251202.jsonl",
    "python_training_20251202.jsonl",
    "python_aprende_book_20251202.jsonl",
    "javascript_training_20251202.jsonl",
    "java_training_20251202.jsonl",
    "rust_go_training_20251202.jsonl",
    "web_training_20251202.jsonl",
    "sql_databases_training_20251202.jsonl",

    # Razonamiento y AGI
    "reasoning_training.jsonl",
    "reasoning_cot.jsonl",

    # Desarrollo
    "thau_developer_20251207_073513.jsonl",
    "thau_advanced_20251207_080734.jsonl",

    # SVG y Assets
    "svg_assets_training.jsonl",
    "project_analysis_training.jsonl",

    # UX/UI
    "ux_chat_format.jsonl",
    "ux_css_frameworks.jsonl",

    # Contabilidad
    "contable_training.jsonl",

    # Agile y DevOps
    "agile_training_20251202.jsonl",
    "devops_training_20251202.jsonl",
    "git_training_20251202.jsonl",

    # Algoritmos y MatemÃ¡ticas
    "algorithms_training_20251202.jsonl",
    "math_training_20251202.jsonl",

    # Tool calling
    "tool_calling.jsonl",

    # Otros
    "thau_v3_clean.jsonl",
    "agent_training.jsonl",
]


def load_jsonl(filepath: Path) -> List[Dict]:
    """Carga un archivo JSONL"""
    entries = []
    if filepath.exists():
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        entries.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
    return entries


def combine_datasets() -> tuple:
    """Combina todos los datasets disponibles"""
    all_entries = []
    stats = {}

    print("\nğŸ“š Combinando datasets...\n")

    for dataset in DATASETS_TO_COMBINE:
        filepath = DATASETS_DIR / dataset
        if filepath.exists():
            entries = load_jsonl(filepath)
            count = len(entries)
            if count > 0:
                all_entries.extend(entries)
                stats[dataset] = count
                print(f"  âœ… {dataset}: {count} ejemplos")
        else:
            print(f"  âš ï¸  {dataset}: no encontrado")

    # Eliminar duplicados basados en instruction
    seen = set()
    unique_entries = []
    for entry in all_entries:
        instruction = entry.get('instruction', '') or entry.get('prompt', '')
        if instruction and instruction not in seen:
            seen.add(instruction)
            unique_entries.append(entry)

    print(f"\nğŸ“Š EstadÃ­sticas:")
    print(f"   Total cargados: {len(all_entries)}")
    print(f"   Ãšnicos: {len(unique_entries)}")
    print(f"   Duplicados eliminados: {len(all_entries) - len(unique_entries)}")

    return unique_entries, stats


def save_combined_dataset(entries: List[Dict]) -> Path:
    """Guarda el dataset combinado"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = OUTPUT_DIR / f"thau_unified_{timestamp}.jsonl"

    with open(output_file, 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')

    print(f"\nğŸ’¾ Dataset guardado: {output_file}")
    print(f"   TamaÃ±o: {output_file.stat().st_size / 1024:.1f} KB")

    return output_file


def create_modelfile(dataset_path: Path) -> Path:
    """Crea el Modelfile para thau-1.1b"""

    modelfile_content = '''# THAU 1.1B - Modelo Unificado con Todas las Capacidades
# ParÃ¡metros: 1.1 Billion
# Creado: ''' + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + '''

FROM tinyllama

SYSTEM """Eres THAU (Thinking Human-like Artificial Understanding), un asistente de IA avanzado con 1.1B parÃ¡metros.

## CAPACIDADES PRINCIPALES

### 1. Desarrollo de Software
- CÃ³digo completo y funcional en mÃºltiples lenguajes
- Python, JavaScript, TypeScript, Java, Rust, Go, SQL
- React, Next.js, FastAPI, Flask, Spring Boot
- Arquitectura limpia, patrones de diseÃ±o, SOLID

### 2. GeneraciÃ³n de Assets
- CreaciÃ³n de SVG (logos, iconos, animaciones)
- DiseÃ±o de interfaces UI/UX
- Sistemas de iconos completos

### 3. Razonamiento Avanzado (Chain of Thought)
- AnÃ¡lisis paso a paso de problemas complejos
- Debugging sistemÃ¡tico
- OptimizaciÃ³n de cÃ³digo

### 4. Desarrollo Ãgil
- Scrum, Kanban, XP
- DevOps, CI/CD, Git workflows
- Testing (unit, integration, e2e)

### 5. Bases de Datos
- SQL avanzado, PostgreSQL, MySQL
- NoSQL, MongoDB, Redis
- DiseÃ±o de esquemas, optimizaciÃ³n

### 6. Contabilidad y Finanzas
- Partida doble, estados financieros
- AnÃ¡lisis de costos, presupuestos

### 7. MatemÃ¡ticas y Algoritmos
- Estructuras de datos
- Algoritmos de ordenamiento y bÃºsqueda
- Complejidad computacional

## FORMATO DE RESPUESTAS

Para cÃ³digo, usa:
**ruta/archivo.ext**
```lenguaje
// cÃ³digo completo y funcional
```

Para SVG:
**nombre.svg**
```svg
<svg>...</svg>
```

Para razonamiento:
### Paso 1: [AnÃ¡lisis]
### Paso 2: [SoluciÃ³n]
### ConclusiÃ³n: [Resultado]

## REGLAS
1. Genera cÃ³digo COMPLETO, nunca fragmentos
2. Explica tu razonamiento cuando sea Ãºtil
3. Usa markdown para formateo claro
4. Responde en el idioma del usuario (espaÃ±ol por defecto)
5. SÃ© conciso pero completo
"""

PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER num_ctx 8192
PARAMETER num_predict 4096
PARAMETER repeat_penalty 1.1
PARAMETER stop "<|im_end|>"
PARAMETER stop "</s>"
'''

    modelfile_path = MODELFILE_DIR / "Modelfile_thau_1.1b"
    with open(modelfile_path, 'w', encoding='utf-8') as f:
        f.write(modelfile_content)

    print(f"\nğŸ“„ Modelfile creado: {modelfile_path}")
    return modelfile_path


def create_model():
    """Crea el modelo en Ollama"""
    print("\nğŸ”¨ Creando modelo thau-1.1b en Ollama...")

    modelfile_path = MODELFILE_DIR / "Modelfile_thau_1.1b"

    try:
        result = subprocess.run(
            ["ollama", "create", "thau-1.1b", "-f", str(modelfile_path)],
            capture_output=True,
            text=True,
            timeout=300
        )

        if result.returncode == 0:
            print("âœ… Modelo thau-1.1b creado exitosamente")

            # Crear alias como latest
            subprocess.run(
                ["ollama", "cp", "thau-1.1b", "thau:latest"],
                capture_output=True,
                timeout=60
            )
            print("âœ… thau:latest actualizado")

            return True
        else:
            print(f"âŒ Error: {result.stderr}")
            return False

    except subprocess.TimeoutExpired:
        print("âŒ Timeout al crear el modelo")
        return False
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False


def show_summary(stats: Dict, total: int):
    """Muestra resumen del entrenamiento"""
    print("\n" + "="*60)
    print("ğŸ“‹ RESUMEN DE THAU-1.1B UNIFIED")
    print("="*60)

    categories = {
        "ProgramaciÃ³n": ["programming", "python", "javascript", "java", "rust", "web", "sql"],
        "Razonamiento": ["reasoning", "cot"],
        "Desarrollo": ["developer", "advanced", "agile", "devops", "git"],
        "Assets/SVG": ["svg", "project_analysis"],
        "UX/UI": ["ux"],
        "Contabilidad": ["contable"],
        "Algoritmos": ["algorithms", "math"],
        "Otros": ["tool_calling", "agent", "v3"]
    }

    for category, keywords in categories.items():
        count = sum(
            v for k, v in stats.items()
            if any(kw in k.lower() for kw in keywords)
        )
        if count > 0:
            print(f"  {category}: {count} ejemplos")

    print(f"\n  TOTAL: {total} ejemplos Ãºnicos")
    print("="*60)


def main():
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             THAU-1.1B UNIFIED TRAINING                       â•‘
â•‘          Combinando todas las capacidades                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # 1. Combinar datasets
    entries, stats = combine_datasets()

    if not entries:
        print("âŒ No se encontraron datos para entrenar")
        return

    # 2. Guardar dataset combinado
    dataset_path = save_combined_dataset(entries)

    # 3. Crear Modelfile
    create_modelfile(dataset_path)

    # 4. Crear modelo en Ollama
    success = create_model()

    # 5. Mostrar resumen
    show_summary(stats, len(entries))

    if success:
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âœ… COMPLETADO                             â•‘
â•‘                                                              â•‘
â•‘  Modelo disponible como:                                     â•‘
â•‘    - thau-1.1b (principal)                                   â•‘
â•‘    - thau:latest (alias)                                     â•‘
â•‘                                                              â•‘
â•‘  Uso: ollama run thau-1.1b                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)


if __name__ == "__main__":
    main()
