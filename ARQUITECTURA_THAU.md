# Arquitectura THAU: Modelo LLM Propio con Capacidades Multimodales

## ğŸ§  Â¿QuÃ© es THAU?

**THAU** es un modelo de lenguaje grande (LLM) **construido desde cero** con las siguientes caracterÃ­sticas Ãºnicas:

1. **Crecimiento Progresivo**: THAU crece desde 18M parÃ¡metros (bebÃ©) hasta 2B parÃ¡metros (adulto)
2. **Auto-Aprendizaje**: Genera sus propias preguntas para aprender continuamente
3. **Auto-Tuning**: Ajusta sus parÃ¡metros basÃ¡ndose en interacciones
4. **Multimodal**: Capacidad de generar imÃ¡genes mediante tool calling
5. **Memoria Multi-Nivel**: Short-term, long-term y episÃ³dica

---

## ğŸ“Š Arquitectura THAU vs TinyLlama

### THAU (Modelo Propio)

```
THAU-2B
â”œâ”€â”€ Arquitectura: Transformer custom (desde cero)
â”œâ”€â”€ ParÃ¡metros: 18M â†’ 2B (progresivo)
â”œâ”€â”€ Edades: 0, 1, 3, 6, 12, 15 aÃ±os
â”œâ”€â”€ Entrenamiento: Auto-questioning + incremental
â”œâ”€â”€ Capacidades:
â”‚   â”œâ”€â”€ GeneraciÃ³n de texto
â”‚   â”œâ”€â”€ Tool calling (generaciÃ³n de imÃ¡genes)
â”‚   â”œâ”€â”€ Self-learning
â”‚   â””â”€â”€ Memoria multi-nivel
â””â”€â”€ Estado: En desarrollo
```

### TinyLlama (Prototipo Temporal)

```
TinyLlama-1.1B-Chat
â”œâ”€â”€ Uso: Prototipo para probar tool calling
â”œâ”€â”€ ParÃ¡metros: 1.1B (fijo)
â”œâ”€â”€ Entrenamiento: Fine-tuning con LoRA
â”œâ”€â”€ PropÃ³sito: Validar sistema antes de entrenar THAU
â””â”€â”€ Estado: Usado solo para pruebas
```

---

## ğŸ¯ Roadmap de Desarrollo

### Fase 1: âœ… Sistema de Tool Calling (Completada)
**Objetivo**: DiseÃ±ar y probar el sistema de tool calling

**QuÃ© se hizo**:
- âœ… Dataset de tool calling (30 ejemplos)
- âœ… Sistema de detecciÃ³n de herramientas
- âœ… IntegraciÃ³n con Stable Diffusion
- âœ… API REST para generaciÃ³n de imÃ¡genes
- âœ… Prueba de concepto con TinyLlama

**Resultado**: Sistema validado y funcionando

---

### Fase 2: ğŸ”„ Entrenamiento de THAU-2B (En Curso)
**Objetivo**: Entrenar THAU desde cero hasta 2B parÃ¡metros

**Archivos clave**:
- `train_thau_2b.py` - Script de entrenamiento progresivo
- `thau_trainer/own_model_manager.py` - Gestor de crecimiento
- `thau_trainer/self_questioning.py` - Auto-generaciÃ³n de preguntas
- `thau_trainer/self_learning.py` - DetecciÃ³n de gaps de conocimiento

**Edades de THAU**:

```python
# Age 0 - BebÃ© (18M parÃ¡metros)
{
    "d_model": 384,
    "n_heads": 6,
    "n_layers": 6,
    "d_ff": 1536,
}

# Age 1 - Infante (50M parÃ¡metros)
{
    "d_model": 512,
    "n_heads": 8,
    "n_layers": 8,
    "d_ff": 2048,
}

# Age 3 - NiÃ±o (150M parÃ¡metros)
{
    "d_model": 768,
    "n_heads": 12,
    "n_layers": 12,
    "d_ff": 3072,
}

# Age 6 - Escolar (400M parÃ¡metros)
{
    "d_model": 1024,
    "n_heads": 16,
    "n_layers": 16,
    "d_ff": 4096,
}

# Age 12 - Adolescente (1B parÃ¡metros)
{
    "d_model": 1536,
    "n_heads": 24,
    "n_layers": 20,
    "d_ff": 6144,
}

# Age 15 - THAU-2B Adulto (2B parÃ¡metros)
{
    "d_model": 2560,
    "n_heads": 32,
    "n_layers": 24,
    "d_ff": 10240,
}
```

**Estado actual**: Entrenamiento en background

---

### Fase 3: â³ IntegraciÃ³n de Tool Calling en THAU (Pendiente)
**Objetivo**: Entrenar THAU-2B con capacidad de tool calling

**Cuando THAU-2B estÃ© listo**:

1. **Entrenar con dataset de tool calling**:
   ```bash
   python train_thau_tool_calling.py \
       --model-checkpoint ./data/checkpoints/thau_2b/age_15 \
       --dataset ./data/datasets/tool_calling_dataset.json \
       --epochs 5
   ```

2. **Exportar THAU-2B con tool calling**:
   ```bash
   python export_thau_to_gguf.py \
       --checkpoint ./data/checkpoints/thau_2b_tool_calling \
       --output thau-2b-multimodal
   ```

3. **Importar a Ollama**:
   ```bash
   ollama create thau-2b-multimodal -f Modelfile-thau-2b
   ```

---

## ğŸ”„ Flujo de Trabajo Actual

### Lo Que Funciona AHORA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sistema de GeneraciÃ³n de ImÃ¡genes (Listo) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. API REST
   â”œâ”€â”€ POST /vision/generate
   â”œâ”€â”€ POST /vision/chat (con detecciÃ³n automÃ¡tica)
   â”œâ”€â”€ GET /vision/image/{filename}
   â””â”€â”€ GET /vision/stats

2. GeneraciÃ³n Directa
   python -c "
   from capabilities.vision.image_generator import ThauImageGenerator
   gen = ThauImageGenerator()
   result = gen.generate_image('a robot learning to code')
   "

3. Demo Interactivo
   python demo_image_generation.py
```

### Lo Que VendrÃ¡ DESPUÃ‰S (con THAU-2B)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        THAU-2B con Tool Calling             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usuario: "Genera una imagen de un gato espacial"
   â†“
THAU-2B (modelo propio) detecta: Necesita tool calling
   â†“
THAU-2B genera: <TOOL:generate_image>{"prompt": "..."}</TOOL>
   â†“
Sistema parsea y ejecuta
   â†“
Imagen generada y mostrada
```

---

## ğŸ“ Estructura de Archivos

```
my-llm/
â”œâ”€â”€ ARQUITECTURA_THAU.md                    # Este archivo
â”‚
â”œâ”€â”€ THAU (Modelo Propio - En desarrollo)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ base_transformer.py         # Arquitectura THAU
â”‚   â”œâ”€â”€ thau_trainer/
â”‚   â”‚   â”œâ”€â”€ own_model_manager.py           # Gestor de crecimiento
â”‚   â”‚   â”œâ”€â”€ self_questioning.py            # Auto-aprendizaje
â”‚   â”‚   â””â”€â”€ self_learning.py               # DetecciÃ³n de gaps
â”‚   â”œâ”€â”€ train_thau_2b.py                   # Entrenamiento progresivo
â”‚   â””â”€â”€ data/checkpoints/thau_2b/          # Checkpoints por edad
â”‚
â”œâ”€â”€ Sistema de Tool Calling (Completado)
â”‚   â”œâ”€â”€ data/datasets/
â”‚   â”‚   â””â”€â”€ tool_calling_dataset.json      # 30 ejemplos
â”‚   â”œâ”€â”€ capabilities/
â”‚   â”‚   â”œâ”€â”€ vision/
â”‚   â”‚   â”‚   â””â”€â”€ image_generator.py         # Stable Diffusion
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â””â”€â”€ tool_registry.py           # DetecciÃ³n automÃ¡tica
â”‚   â”œâ”€â”€ api/routes/
â”‚   â”‚   â””â”€â”€ vision.py                      # Endpoints REST
â”‚   â””â”€â”€ thau_chat.py                       # CLI integrada
â”‚
â”œâ”€â”€ Prototipo TinyLlama (Solo pruebas)
â”‚   â”œâ”€â”€ train_tool_calling.py              # Prueba de concepto
â”‚   â”œâ”€â”€ export_tool_calling.py             # Export a Ollama
â”‚   â””â”€â”€ data/checkpoints/incremental/
â”‚       â””â”€â”€ tool_calling_final/            # Fine-tune temporal
â”‚
â””â”€â”€ DocumentaciÃ³n
    â”œâ”€â”€ GUIA_GENERACION_IMAGENES.md        # Uso de imÃ¡genes
    â”œâ”€â”€ GUIA_TOOL_CALLING.md               # Tool calling completo
    â””â”€â”€ RESUMEN_TOOL_CALLING.md            # Resumen ejecutivo
```

---

## ğŸš€ CÃ³mo Usar AHORA (Sin THAU-2B aÃºn)

### Generar ImÃ¡genes Directamente

**OpciÃ³n 1: API REST**
```bash
# Terminal 1: Iniciar API
python api/main.py

# Terminal 2: Generar imagen
curl -X POST "http://localhost:8000/vision/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a cute robot", "width": 512, "height": 512}'
```

**OpciÃ³n 2: Python Directo**
```python
from capabilities.vision.image_generator import ThauImageGenerator

gen = ThauImageGenerator()
result = gen.generate_image("un gato espacial, digital art")

if result['success']:
    print(f"Imagen: {result['path']}")
```

**OpciÃ³n 3: Demo**
```bash
python demo_image_generation.py --demo 1
```

---

## ğŸ¯ PrÃ³ximos Pasos

### 1. Completar THAU-2B Base â³
```bash
# Monitorear entrenamiento
tail -f data/training_output.log

# O revisar progreso
python -c "
from thau_trainer.own_model_manager import ThauOwnModelManager
manager = ThauOwnModelManager()
print(manager.get_training_stats())
"
```

### 2. Entrenar THAU-2B con Tool Calling â³
Cuando age 15 estÃ© completo:
```bash
python train_thau_tool_calling.py \
    --base-model ./data/checkpoints/thau_2b/age_15 \
    --dataset ./data/datasets/tool_calling_dataset.json
```

### 3. Exportar THAU-2B Completo â³
```bash
python export_thau_to_gguf.py \
    --model-path ./data/checkpoints/thau_2b_multimodal \
    --output-name thau-2b-multimodal
```

### 4. Deploy Final â³
```bash
ollama create thau-2b -f Modelfile-thau-2b
python thau_chat.py --model thau-2b
```

---

## ğŸ” Diferencias Clave

| Aspecto | THAU (Propio) | TinyLlama (Temporal) |
|---------|---------------|----------------------|
| **PropÃ³sito** | Modelo final de producciÃ³n | Prototipo para validar tool calling |
| **Arquitectura** | Custom desde cero | Pre-entrenado de HuggingFace |
| **ParÃ¡metros** | 18M â†’ 2B (progresivo) | 1.1B (fijo) |
| **Entrenamiento** | Self-questioning + bootstrap | Fine-tuning con LoRA |
| **Crecimiento** | Edades 0-15 | No aplica |
| **Estado** | En desarrollo | Solo para pruebas |
| **Uso final** | ProducciÃ³n | Descartado despuÃ©s de validar |

---

## ğŸ“Š Estado Actual del Proyecto

### âœ… Completado
- [x] Sistema de generaciÃ³n de imÃ¡genes (Stable Diffusion)
- [x] API REST para tool calling
- [x] Dataset de tool calling (30 ejemplos)
- [x] DetecciÃ³n automÃ¡tica de herramientas
- [x] Prototipo con TinyLlama (validaciÃ³n)
- [x] DocumentaciÃ³n completa

### ğŸ”„ En Progreso
- [ ] Entrenamiento THAU-2B (age 0 â†’ 15)
- [ ] Sistema de self-questioning activo
- [ ] GeneraciÃ³n de datasets automÃ¡tica

### â³ Pendiente
- [ ] Integrar tool calling en THAU-2B
- [ ] Exportar THAU-2B a GGUF
- [ ] Deploy en Ollama
- [ ] Testing end-to-end con THAU propio

---

## ğŸ’¡ VisiÃ³n Final

**THAU-2B Multimodal** serÃ¡ un modelo:

1. **Construido desde cero** (no fine-tune)
2. **Auto-aprendizaje** continuo
3. **Multimodal** (texto + imÃ¡genes)
4. **Memoria persistente** (short/long/episodic)
5. **Tool calling nativo**
6. **Deployable** (Ollama, API, CLI)

**Tiempo estimado**:
- Entrenamiento THAU-2B base: 5-10 horas (en curso)
- Tool calling integration: 30-60 minutos (cuando base estÃ© listo)
- Export y deploy: 10-15 minutos

---

**Estado**: Sistema de tool calling validado âœ…
**Siguiente hito**: THAU-2B age 15 completado ğŸ”„
**Objetivo final**: THAU-2B multimodal en producciÃ³n ğŸ¯
