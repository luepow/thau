# THAU: LLM Propio con Auto-Aprendizaje y Capacidades Multimodales

## ğŸ§  Â¿QuÃ© es THAU?

**THAU** es un modelo de lenguaje grande (LLM) **construido desde cero** con:

- ğŸŒ± **Crecimiento Progresivo**: De 18M a 2B parÃ¡metros (edades 0-15)
- ğŸ“ **Auto-Aprendizaje**: Genera sus propias preguntas para aprender
- ğŸ”§ **Auto-Tuning**: Ajuste continuo basado en interacciones
- ğŸ¨ **Multimodal**: Genera imÃ¡genes mediante tool calling
- ğŸ’¾ **Memoria Multi-Nivel**: Short-term, long-term, episÃ³dica

---

## ğŸ“Š Estado Actual

### âœ… Lo Que Ya Funciona

1. **Sistema de GeneraciÃ³n de ImÃ¡genes**
   - Stable Diffusion v1.5 integrado
   - API REST funcionando
   - GeneraciÃ³n directa desde Python
   - Demo interactivo

2. **Tool Calling**
   - Dataset de 30 ejemplos creado
   - DetecciÃ³n automÃ¡tica de herramientas
   - Sistema validado con prototipo

3. **Infraestructura THAU**
   - Arquitectura transformer custom
   - Sistema de crecimiento progresivo
   - Self-questioning activo
   - Entrenamiento en curso

### ğŸ”„ En Desarrollo

- **THAU-2B Base**: Entrenamiento progresivo (age 0 â†’ 15)
- **IntegraciÃ³n Multimodal**: Pendiente cuando base estÃ© listo

---

## ğŸš€ Quick Start

### Generar ImÃ¡genes AHORA

Mientras THAU-2B se entrena, puedes usar el sistema de imÃ¡genes:

```bash
# 1. Activar entorno
cd /Users/lperez/Workspace/Development/fullstack/thau_1_0/my-llm
source venv/bin/activate

# 2. Iniciar API
python api/main.py

# 3. En navegador
# http://localhost:8000/docs
```

O desde Python:

```python
from capabilities.vision.image_generator import ThauImageGenerator

gen = ThauImageGenerator()
result = gen.generate_image("un robot aprendiendo, digital art")

if result['success']:
    print(f"Imagen guardada: {result['path']}")
```

### Ver Progreso de THAU-2B

```bash
# Ver entrenamiento en tiempo real
tail -f data/training_output.log

# O revisar checkpoints
ls -lh data/checkpoints/thau_2b/
```

---

## ğŸ“ Estructura del Proyecto

```
my-llm/
â”œâ”€â”€ ğŸ“˜ ARQUITECTURA_THAU.md           # Arquitectura completa
â”œâ”€â”€ ğŸ“˜ README_THAU.md                 # Este archivo
â”‚
â”œâ”€â”€ ğŸ§  THAU (Modelo Propio)
â”‚   â”œâ”€â”€ core/models/                  # Arquitectura transformer
â”‚   â”œâ”€â”€ thau_trainer/                 # Sistema de entrenamiento
â”‚   â”‚   â”œâ”€â”€ own_model_manager.py     # Gestor de crecimiento
â”‚   â”‚   â”œâ”€â”€ self_questioning.py      # Auto-preguntas
â”‚   â”‚   â””â”€â”€ self_learning.py         # DetecciÃ³n de gaps
â”‚   â”œâ”€â”€ train_thau_2b.py             # Script principal
â”‚   â””â”€â”€ data/checkpoints/thau_2b/    # Por edad (0-15)
â”‚
â”œâ”€â”€ ğŸ¨ Sistema Multimodal
â”‚   â”œâ”€â”€ capabilities/vision/          # GeneraciÃ³n imÃ¡genes
â”‚   â”œâ”€â”€ capabilities/tools/           # Tool calling
â”‚   â”œâ”€â”€ api/routes/vision.py         # REST API
â”‚   â””â”€â”€ demo_image_generation.py     # Demo
â”‚
â””â”€â”€ ğŸ“š DocumentaciÃ³n
    â”œâ”€â”€ GUIA_GENERACION_IMAGENES.md
    â”œâ”€â”€ GUIA_TOOL_CALLING.md
    â””â”€â”€ RESUMEN_TOOL_CALLING.md
```

---

## ğŸ¯ Roadmap

### Fase 1: âœ… Sistema Multimodal (Completado)
- [x] IntegraciÃ³n Stable Diffusion
- [x] API REST
- [x] Dataset tool calling
- [x] ValidaciÃ³n con prototipo

### Fase 2: ğŸ”„ THAU-2B Base (En Curso)
- [ ] Age 0 - BebÃ© (18M)
- [ ] Age 1 - Infante (50M)
- [ ] Age 3 - NiÃ±o (150M)
- [ ] Age 6 - Escolar (400M)
- [ ] Age 12 - Adolescente (1B)
- [ ] Age 15 - Adulto (2B) â­

### Fase 3: â³ THAU-2B Multimodal (Pendiente)
- [ ] Integrar tool calling
- [ ] Exportar a GGUF
- [ ] Deploy en Ollama
- [ ] Testing end-to-end

---

## ğŸ’» Uso

### GeneraciÃ³n de ImÃ¡genes

**MÃ©todo 1: API (Recomendado)**

```bash
# Iniciar API
python api/main.py

# Abrir en navegador
http://localhost:8000/docs
```

**MÃ©todo 2: Python Directo**

```python
from capabilities.vision.image_generator import ThauImageGenerator

gen = ThauImageGenerator()

# Generar imagen
result = gen.generate_image(
    prompt="a futuristic city, cyberpunk style",
    num_inference_steps=30,
    width=512,
    height=512
)

print(f"Imagen: {result['path']}")
```

**MÃ©todo 3: Demo Interactivo**

```bash
python demo_image_generation.py --demo 1
```

**MÃ©todo 4: cURL**

```bash
curl -X POST "http://localhost:8000/vision/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a cute robot learning to code",
    "width": 512,
    "height": 512
  }'
```

### Monitorear THAU-2B

```bash
# Ver logs de entrenamiento
tail -f data/training_output.log

# Revisar checkpoints por edad
ls data/checkpoints/thau_2b/

# Stats de entrenamiento
python -c "
from thau_trainer.own_model_manager import ThauOwnModelManager
manager = ThauOwnModelManager()
stats = manager.get_training_stats()
print(stats)
"
```

---

## ğŸ”§ InstalaciÃ³n

### Requisitos

- Python 3.10+
- PyTorch 2.0+
- 8GB+ RAM (16GB+ recomendado)
- GPU opcional (MPS/CUDA)

### Setup

```bash
# 1. Clonar repo
git clone <repo>
cd my-llm

# 2. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Instalar dependencias de imÃ¡genes
pip install diffusers Pillow accelerate transformers

# 5. Verificar instalaciÃ³n
python -c "from capabilities.vision.image_generator import ThauImageGenerator; print('âœ… OK')"
```

---

## ğŸ“– DocumentaciÃ³n

- **[ARQUITECTURA_THAU.md](ARQUITECTURA_THAU.md)** - Arquitectura completa y roadmap
- **[GUIA_GENERACION_IMAGENES.md](GUIA_GENERACION_IMAGENES.md)** - Uso de imÃ¡genes detallado
- **[GUIA_TOOL_CALLING.md](GUIA_TOOL_CALLING.md)** - Sistema de tool calling completo

---

## ğŸ¤ CaracterÃ­sticas Ãšnicas de THAU

### 1. Crecimiento Progresivo

THAU crece como un humano:

| Edad | ParÃ¡metros | Capacidades |
|------|-----------|-------------|
| 0 aÃ±os | 18M | Conceptos bÃ¡sicos |
| 1 aÃ±o | 50M | Vocabulario ampliado |
| 3 aÃ±os | 150M | Razonamiento simple |
| 6 aÃ±os | 400M | Conocimiento escolar |
| 12 aÃ±os | 1B | Razonamiento complejo |
| 15 aÃ±os | 2B | Adulto completo |

### 2. Auto-Aprendizaje

```python
# THAU genera sus propias preguntas
from thau_trainer.self_questioning import SelfQuestioningSystem

questioner = SelfQuestioningSystem()
questions = questioner.generate_questions(
    topic="programaciÃ³n",
    num_questions=10
)
# THAU se auto-entrena con estas preguntas
```

### 3. DetecciÃ³n de Gaps

```python
# THAU detecta quÃ© no sabe
from thau_trainer.self_learning import SelfLearningManager

learner = SelfLearningManager()
gaps = learner.detect_knowledge_gaps(
    conversation_history=[...]
)
# Genera datasets para llenar gaps
```

### 4. Memoria Multi-Nivel

```python
from memory.manager import MemoryManager

memory = MemoryManager()

# Short-term (conversaciÃ³n actual)
memory.update_context("user", "Hola THAU")

# Long-term (RAG con ChromaDB)
memory.remember("Python es un lenguaje interpretado", importance=8)

# Episodic (experiencias pasadas)
memory.recall("Â¿quÃ© hablamos ayer?")
```

---

## ğŸ¨ Ejemplos de Uso

### GeneraciÃ³n de ImÃ¡genes

```python
from capabilities.vision.image_generator import ThauImageGenerator

gen = ThauImageGenerator()

# Simple
gen.generate_image("a cat in space")

# Avanzado
gen.generate_image(
    prompt="futuristic city at sunset, cyberpunk, neon lights",
    negative_prompt="blurry, low quality",
    num_inference_steps=50,
    guidance_scale=8.0,
    width=768,
    height=512,
    seed=42  # Reproducible
)

# Batch
gen.generate_batch([
    "a robot learning",
    "abstract AI visualization",
    "recursive mirrors"
])
```

### Tool Calling (Futuro con THAU-2B)

```python
# Cuando THAU-2B estÃ© listo
from thau_chat import ThauChat

chat = ThauChat(model="thau-2b-multimodal")

# THAU detectarÃ¡ automÃ¡ticamente
chat.send_message("Genera una imagen de un perro astronauta")

# Output:
# ğŸ¤– THAU: Â¡Claro! Generando imagen...
# ğŸ¨ Imagen creada: /vision/image/astronaut_dog.png
```

---

## ğŸ“Š Performance

### GeneraciÃ³n de ImÃ¡genes

- **Primera carga**: ~15-20 min (descarga modelo 4GB)
- **GeneraciÃ³n**: 30-60 seg/imagen (512x512, 30 steps)
- **Calidad**: Configurable (10-100 steps)
- **ResoluciÃ³n**: 256x256 hasta 1024x1024

### THAU-2B (Estimado)

- **Entrenamiento Age 0-15**: 5-10 horas (GPU)
- **Inference**: ~100-200 tokens/seg (GPU)
- **TamaÃ±o GGUF**: ~4-5 GB (F16)
- **RAM mÃ­nimo**: 8GB (cuantizado), 16GB (full)

---

## ğŸ› Troubleshooting

### "CUDA out of memory"

```python
# Reducir resoluciÃ³n o pasos
gen.generate_image(
    prompt="...",
    width=384,      # Reducir
    height=384,
    num_inference_steps=20  # Reducir
)
```

### "Model not found"

```bash
# Limpiar cachÃ©
rm -rf ~/.cache/huggingface/

# Re-ejecutar (descargarÃ¡ automÃ¡ticamente)
python demo_image_generation.py
```

### Ver progreso de THAU-2B

```bash
# Si no hay output visible
python -c "
import glob
checkpoints = glob.glob('data/checkpoints/thau_2b/*')
print(f'Checkpoints: {len(checkpoints)}')
for cp in sorted(checkpoints):
    print(f'  - {cp}')
"
```

---

## ğŸš€ PrÃ³ximos Pasos

1. **Monitorear THAU-2B**: `tail -f data/training_output.log`
2. **Usar generaciÃ³n de imÃ¡genes**: `python api/main.py`
3. **Cuando THAU-2B complete**: Integrar tool calling
4. **Deploy final**: Ollama + API + CLI

---

## ğŸ“ Comandos RÃ¡pidos

```bash
# Generar imagen (una lÃ­nea)
python -c "from capabilities.vision.image_generator import ThauImageGenerator; ThauImageGenerator().generate_image('a robot')"

# Iniciar API
python api/main.py

# Demo completo
python demo_image_generation.py

# Ver progreso THAU
tail -f data/training_output.log

# Stats
python -c "from thau_trainer.own_model_manager import ThauOwnModelManager; print(ThauOwnModelManager().get_training_stats())"
```

---

## ğŸ¯ VisiÃ³n Final

**THAU-2B serÃ¡**:
- âœ… Modelo LLM propio (no fine-tune)
- âœ… Auto-aprendizaje continuo
- âœ… Multimodal (texto + imÃ¡genes)
- âœ… Memoria persistente
- âœ… Tool calling nativo
- âœ… Deployable (Ollama/API/CLI)

**Estado Actual**:
- ğŸ¨ Sistema de imÃ¡genes: âœ… Listo
- ğŸ§  THAU-2B base: ğŸ”„ En entrenamiento
- ğŸ”— IntegraciÃ³n: â³ Cuando base estÃ© listo

---

**Creado con**: PyTorch, Transformers, Stable Diffusion, FastAPI
**Autor**: Luis PÃ©rez
**Ãšltima actualizaciÃ³n**: 2025-01-15
